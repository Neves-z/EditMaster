# EditMaster: Bridging Text Instruction and Visual Example for Multimodal Guided Image Editing

ğŸ“„ **Paper:** [ACM MM 2025](https://doi.org/10.1145/3746027.3754926)  
ğŸ« **Authors:** Jiahui Zhang, Mengtian Li*, Jiewei Tang, Junyu Deng, Siyu Tian, Xiang Liu, Meng Zhang, Guangnan Ye*, Yu-Gang Jiang  
(*Corresponding author)

---

## ğŸ§© Overview
**EditMaster** is a unified multimodal image editing framework that integrates **text instructions** and **visual examples**.  
By combining semantic understanding and visual fidelity, EditMaster enables flexible, fine-grained, and context-aware image editing â€” going beyond the limitations of unimodal methods.

<p align="center">
  <img src="Assets/pipeline.png" width="700">
</p>

---

## ğŸš€ Highlights
- ğŸ”¹ Unified **multimodal instruction-guided editing** framework  
- ğŸ”¹ **MDREA (Mask-based Decoupled Residual Exemplar-Attention)** module for precise, region-aware editing  
- ğŸ”¹ **Pre-edit visual guidance** via Multimodal Large Language Models (MLLMs)  
- ğŸ”¹ Efficient **MultiEdit dataset** construction pipeline

---

## ğŸ“… Code Availability
The official implementation of **EditMaster** is **coming soon** ğŸ§‘â€ğŸ’»  
We are currently organizing the codebase and preparing documentation for public release.  
Stay tuned â€” the full code, pretrained models, and MultiEdit dataset will be available here shortly!

---

## ğŸ“Š Dataset
> ğŸ”— http://150.158.167.199:8080/files/MultiEdit-v1/

---

## ğŸ“œ Citation
If you find this work useful, please consider citing our paper:
```bibtex
@inproceedings{zhang2025editmaster,
  title={EditMaster: Bridging Text Instruction and Visual Example for Multimodal Guided Image Editing},
  author={Zhang, Jiahui and Li, Mengtian and Tang, Jiewei and Deng, Junyu and Tian, Siyu and Liu, Xiang and Zhang, Meng and Ye, Guangnan and Jiang, Yu-Gang},
  booktitle={Proceedings of the 33rd ACM International Conference on Multimedia},
  year={2025}
}
